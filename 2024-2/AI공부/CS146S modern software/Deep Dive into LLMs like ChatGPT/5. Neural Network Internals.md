신경망 내부에서는 가중치(파라미터)를 사용한 수학식을 사용해 각 토큰의 확률을 조정한다.
이 파라미터들은 DJ 세트의 노브처럼 생각하면 비슷하다. 이 노브들을 돌리면서(조정하면서)
가능한 모든 토큰 시퀀스 입력에 대해 다른 예측을 얻을 수 있다.

**신경망 훈련 == 훈련 세트의 통계와 일관되어 보이는 파라미터 설정을 발견하는 것

신경망 내 수학적 표현은
![[Pasted image 20260201023933.png]]
이렇게 생겼는데, 효과적인 표현식을 설꼐하는 게 신경망 아키텍쳐 연구의 주제다
표현력이 있고, 최적화 가능하고, 병렬화 가능한 등등

https://bbycroft.net/llm
여기서 트랜스포머 네트워크의 시각화를 볼 수 있다.
logit softmax가 출력인데, 이것이 다음에 어떤 토큰이 올 지에 대한 예측이다.

이 토큰들은 분산 표현으로 임베딩된다
모든 토큰은 신경망 내부에서 그것을 나타내는 일종의 벡터를 가지고 있다
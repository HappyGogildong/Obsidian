신경망에 인간과 시스템의 상호작용을 학습시키기 위해 
명시적 프로그래밍이 아닌, **대화 예시를** 주어 학습시킨다.

**인간 라벨러**를 고용해 다양한 주제, 여러 턴과 길이를 가진 대화 데이터셋을 만든다.
라벨러는 어시스턴트의 이상적인 응답을 작성한다. 
![[Pasted image 20260204022025.png]]
(실제 라벨러에게 주어지는 지침)
이 대화 데이터셋을 아까 만든 base model에 계속 학습시킨다.
그렇게 모델을 조정시키면, 추론 시에 인간 라벨러의 대화를 모방한 응답을 얻을 수 있다.

이 대화 데이터도 토큰 시퀀스로 변환되어야 하기에, 인코딩을 설계해야한다.
![[Pasted image 20260204022213.png]]
이 형식이나 프로토콜은 LLM마다 다르다. 
위 사진은 GPT-4o의 예시인데, im_start라는 특수한 토큰이 있고, 
user를 지정한다. 그 다음 독백 구분자가 오고, 질문의 토큰이 오게 된다.
그 다음 닫는 토큰 im_end가 온다.

여기서 im_으로 시작하는 것들은 텍스트가 아닌 추가된 특수 토큰이다.
모델이 "이것은 턴의 시작이고, 누구를 위한 것인가, 사용자를 위한 턴의 시작이고, 이것이 사용자가 말하는 것이고, 사용자가 끝나고, 새로운 턴의 시작이고, 어시스턴트의 턴이고, 어시스턴트가 무엇을 말하는가, 이것이 어시스턴트가 말하는 토큰들이다" 등을 배우도록 한다.

그렇게 대화를 1차원 토큰 시퀀스로 바꾼다(Base Model 학습에 쓰인 데이터와 같은 input형식)
그러면 이전처럼 대화를 표현하고, 학습할 수 있다.

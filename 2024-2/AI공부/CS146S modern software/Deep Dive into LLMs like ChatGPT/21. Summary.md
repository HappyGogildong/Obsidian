모델을 훈련하는 세 가지 주요 단계와 패러다임을 간단히 알아보았다.
**Pretraining**, **Supervised Fine Tuning**, **Reinforcement Learning**.

사전학습은 설명을 읽는 기본적인 지식 습득,
지도학습 fine tuning은 예제 풀이를 보고 전문가를 모방하는 것이고,
RL은 연습문제이다.

대부분의 분야에서 잘 작동하기 위해 교과서를 작성하고 고수준에서 제시한(간단히 알아본) 알고리즘을 정제해야한다.

이 모델은 작업을 위한 도구로써 유용하지만, 완전히 신뢰할 수 없다. 
환각은 완화책은 있지만 완벽할 수 없다.

LLM의 스위스 치즈 모델이라는 것이 있다.
올림피아드 문제처럼 어려운 문제를 풀 수 있지만, 9.11 9.9 대소비교 문제를 틀리는 등
치즈처럼 이상한 구멍이 나있다.
딥시크 R1의 논문은 강화학습 미세조정에 대해 자세하게 다룬 논문 중 하나이다.
![[Pasted image 20260205223631.png]]
이것은 수학 문제를 푸는 것이 개선되어가는 그래프이다. 수천 번의 업데이트를 반복하며 정확도가 계속 올라간다.
![[Pasted image 20260205223828.png]]
여기 그래프를 보면, 최적화 후반에 모델의 **응답당 평균 길이가 올라가는 것**을 볼 수 있다.
모델이 더 높은 정확도를 얻기 위해 더 많은 토큰을 사용하는 것처럼 보인다.

![[Pasted image 20260205224002.png]]
저 빨간 글씨 부근에서 모델은 단계를 재평가하고 있다.
정확도를 위해 많은 아이디어를 시도하고, 다른 관점에서 시도하고, 되추적, 재구성, 백트래킹을 하는 것이 더 낫다는 것을 배웠다.
이는 사람이 수학 문제 해결 과정에 사용하는 것과 비슷하다.